{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c9230e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (79.0.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7d877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found input file at: /Users/kanishkaman/Desktop/Fusion_proj/epi_r.csv\n",
      "Attempting to load data from: /Users/kanishkaman/Desktop/Fusion_proj/epi_r.csv\n",
      "Successfully loaded 20052 rows.\n",
      "Selected relevant columns: ['title', 'rating', 'calories', 'protein', 'fat', 'sodium', 'vegetarian', 'vegan', 'kosher', 'healthy', 'dessert', 'drink']\n",
      "Rows before dropping NaNs in essentials: 20052\n",
      "Rows after dropping NaNs in essentials: 15864\n",
      "Rows before dropping NaNs after type conversion: 15864\n",
      "Rows after dropping NaNs after type conversion: 15864\n",
      "Rows before removing invalid data: 15864\n",
      "Rows after removing invalid data: 15716\n",
      "An error occurred during data cleaning: name '__file__' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/z_/h4czh9p97wxgh97wpnc1gj7m0000gn/T/ipykernel_56850/1483019420.py\", line 90, in clean_recipe_data\n",
      "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
      "                                                 ^^^^^^^^\n",
      "NameError: name '__file__' is not defined. Did you mean: '__name__'?\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # --- Configuration ---\n",
    "# # Define the path to the raw data file relative to this script\n",
    "# RAW_DATA_FILE = 'epi_r.csv'\n",
    "# # Define the path where the cleaned data will be saved\n",
    "# CLEANED_DATA_FILE = 'recipes_cleaned.csv'\n",
    "# # Define essential columns needed for the app\n",
    "# ESSENTIAL_COLUMNS = ['title', 'rating', 'calories', 'protein', 'fat', 'sodium']\n",
    "# # Define potential dietary/tag columns to keep (adjust based on exact column names in your file)\n",
    "# # Check your epi_r.csv for the exact names (e.g., 'glutenFree' vs 'gluten free')\n",
    "# TAG_COLUMNS = [\n",
    "#     'vegetarian', 'vegan', 'glutenFree', 'dairyFree', 'peanutFree',\n",
    "#     'soyFree', 'treeNutFree', 'kosher', 'healthy', 'lowCal', 'lowFat',\n",
    "#     'lowSodium', 'dessert', 'drink' # Add other relevant tags if needed\n",
    "# ]\n",
    "\n",
    "\n",
    "# # --- Main Cleaning Function ---\n",
    "# def clean_recipe_data(input_filepath, output_filepath):\n",
    "#     \"\"\"\n",
    "#     Loads, cleans, and saves the recipe data.\n",
    "#     \"\"\"\n",
    "#     print(f\"Attempting to load data from: {input_filepath}\")\n",
    "#     try:\n",
    "#         # Load the raw dataset\n",
    "#         df = pd.read_csv(input_filepath)\n",
    "#         print(f\"Successfully loaded {len(df)} rows.\")\n",
    "\n",
    "#         # --- 1. Select Relevant Columns ---\n",
    "#         # Check which tag columns actually exist in the loaded dataframe\n",
    "#         existing_tag_columns = [col for col in TAG_COLUMNS if col in df.columns]\n",
    "#         columns_to_keep = ESSENTIAL_COLUMNS + existing_tag_columns\n",
    "        \n",
    "#         # Ensure 'title' exists, as it's crucial\n",
    "#         if 'title' not in df.columns:\n",
    "#             print(\"Error: 'title' column not found in the dataset. Cannot proceed.\")\n",
    "#             return\n",
    "\n",
    "#         # Keep only the necessary columns + existing tags\n",
    "#         df = df[columns_to_keep]\n",
    "#         print(f\"Selected relevant columns: {list(df.columns)}\")\n",
    "\n",
    "#         # --- 2. Handle Missing Values ---\n",
    "#         # Drop rows where essential nutritional info or title is missing\n",
    "#         print(f\"Rows before dropping NaNs in essentials: {len(df)}\")\n",
    "#         df = df.dropna(subset=ESSENTIAL_COLUMNS)\n",
    "#         print(f\"Rows after dropping NaNs in essentials: {len(df)}\")\n",
    "\n",
    "#         # Fill NaNs in tag columns with 0 (assuming missing means 'false')\n",
    "#         for col in existing_tag_columns:\n",
    "#              df[col] = df[col].fillna(0)\n",
    "\n",
    "#         # --- 3. Ensure Correct Data Types ---\n",
    "#         # Convert nutritional columns and rating to numeric (float)\n",
    "#         for col in ['rating', 'calories', 'protein', 'fat', 'sodium']:\n",
    "#             if col in df.columns:\n",
    "#                 df[col] = pd.to_numeric(df[col], errors='coerce') # Coerce errors will turn problematic values into NaN\n",
    "\n",
    "#         # Convert tag columns to integers (0 or 1)\n",
    "#         for col in existing_tag_columns:\n",
    "#              # Check if column is already numeric-like before converting\n",
    "#              if pd.api.types.is_numeric_dtype(df[col]):\n",
    "#                  df[col] = df[col].astype(int)\n",
    "#              else:\n",
    "#                  # Handle potential non-numeric entries if necessary (e.g., 'True'/'False' strings)\n",
    "#                  # This basic conversion assumes they are mostly 0/1 or NaN already\n",
    "#                  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "\n",
    "#         # Drop rows again if numeric conversion failed for essential columns\n",
    "#         print(f\"Rows before dropping NaNs after type conversion: {len(df)}\")\n",
    "#         df = df.dropna(subset=ESSENTIAL_COLUMNS)\n",
    "#         print(f\"Rows after dropping NaNs after type conversion: {len(df)}\")\n",
    "\n",
    "#         # --- 4. Remove Outliers/Invalid Data ---\n",
    "#         print(f\"Rows before removing invalid data: {len(df)}\")\n",
    "#         # Remove recipes with 0 or negative calories, or excessively high values (adjust thresholds as needed)\n",
    "#         df = df[df['calories'] > 10] # At least 10 calories\n",
    "#         df = df[df['calories'] < 5000] # Less than 5000 calories (adjust as needed)\n",
    "#         # Ensure rating is within a sensible range (e.g., 0-5)\n",
    "#         if 'rating' in df.columns:\n",
    "#             df = df[(df['rating'] >= 0) & (df['rating'] <= 5)]\n",
    "#         print(f\"Rows after removing invalid data: {len(df)}\")\n",
    "\n",
    "#         # --- 5. Save Cleaned Data ---\n",
    "#         if not df.empty:\n",
    "#             # Construct the full output path\n",
    "#             script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "#             full_output_path = os.path.join(script_dir, '..', 'data', output_filepath) # Save to data folder\n",
    "            \n",
    "#             # Create data directory if it doesn't exist\n",
    "#             os.makedirs(os.path.dirname(full_output_path), exist_ok=True) \n",
    "            \n",
    "#             df.to_csv(full_output_path, index=False)\n",
    "#             print(f\"Cleaned data saved successfully to: {full_output_path}\")\n",
    "#         else:\n",
    "#             print(\"Warning: No data left after cleaning. Cleaned file not saved.\")\n",
    "\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: Raw data file not found at {input_filepath}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred during data cleaning: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "\n",
    "# # --- Execution ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Assuming epi_r.csv is in the same directory as this script OR in a 'data' subdirectory\n",
    "#     # Try finding the file in common locations relative to the script\n",
    "#     script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "#     possible_paths = [\n",
    "#         os.path.join(script_dir, RAW_DATA_FILE),\n",
    "#         os.path.join(script_dir, '..', 'data', RAW_DATA_FILE), # If script is in 'models' or similar\n",
    "#         RAW_DATA_FILE # If script is run from the project root\n",
    "#     ]\n",
    "    \n",
    "#     input_path_found = None\n",
    "#     for path in possible_paths:\n",
    "#         if os.path.exists(path):\n",
    "#             input_path_found = path\n",
    "#             break\n",
    "            \n",
    "#     if input_path_found:\n",
    "#          clean_recipe_data(input_path_found, CLEANED_DATA_FILE)\n",
    "#     else:\n",
    "#         print(f\"Error: Could not find the raw data file '{RAW_DATA_FILE}' in expected locations.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
